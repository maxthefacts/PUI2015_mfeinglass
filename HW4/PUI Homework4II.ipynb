{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUI Assignment 4 Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Max Feinglass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binomial sample with increasing p value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "%pylab inline\n",
    "np.random.seed(987654321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generate the NORMAL distribution\n",
    "normal = np.random.randn(1000)\n",
    "threshold = scipy.stats.anderson(normal, dist='norm')[1][scipy.stats.anderson(normal, dist='norm')[2]==[1.0]]\n",
    "def mynorm (x, mu, var):\n",
    "    return scipy.stats.norm.cdf(x, loc=mu, scale=var)\n",
    "\n",
    "#Generate a series of binomial samples with increasing n*p (the mean) value\n",
    "narray = range(1,50,1)\n",
    "ks_b01 = np.zeros(len(narray))\n",
    "ks_b10 = np.zeros(len(narray))\n",
    "ks_b25 = np.zeros(len(narray))\n",
    "ks_b50 = np.zeros(len(narray))\n",
    "ks_b90 = np.zeros(len(narray))\n",
    "ks_b99 = np.zeros(len(narray))\n",
    "\n",
    "ad_b01 = np.zeros(len(narray))\n",
    "ad_b10 = np.zeros(len(narray))\n",
    "ad_b25 = np.zeros(len(narray))\n",
    "ad_b50 = np.zeros(len(narray))\n",
    "ad_b90 = np.zeros(len(narray))\n",
    "ad_b99 = np.zeros(len(narray))\n",
    "\n",
    "kl_b01 = np.zeros(len(narray))\n",
    "kl_b10 = np.zeros(len(narray))\n",
    "kl_b25 = np.zeros(len(narray))\n",
    "kl_b50 = np.zeros(len(narray))\n",
    "kl_b90 = np.zeros(len(narray))\n",
    "kl_b99 = np.zeros(len(narray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform KS Tests, Anderson Tests, and KL tests for each Probablity Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perfrom Tests\n",
    "for i,n in enumerate(narray):\n",
    "    p01=0.01 #parameter for the binomial, my arbitrary choice\n",
    "    p10=0.10\n",
    "    p25=0.25\n",
    "    p50=.50\n",
    "    p90=.90\n",
    "    p99=.99\n",
    "    \n",
    "    #generate the Bionomial Distributions\n",
    "    dist01 = np.random.binomial(n, p01, 1000)\n",
    "    dist10 = np.random.binomial(n, p10, 1000)\n",
    "    dist25 = np.random.binomial(n, p25, 1000)\n",
    "    dist50 = np.random.binomial(n, p50, 1000)\n",
    "    dist90 = np.random.binomial(n, p90, 1000)\n",
    "    dist99 = np.random.binomial(n, p99, 1000)\n",
    "   \n",
    "    #run the K-S tests. \n",
    "    ks_b01[i] = scipy.stats.kstest(dist01, mynorm, args=(n*p01, n*p01*(1.0-p01)))[0]\n",
    "    ks_b10[i] = scipy.stats.kstest(dist10, mynorm, args=(n*p10, n*p10*(1.0-p10)))[0]\n",
    "    ks_b25[i] = scipy.stats.kstest(dist25, mynorm, args=(n*p25, n*p25*(1.0-p25)))[0]\n",
    "    ks_b50[i] = scipy.stats.kstest(dist50, mynorm, args=(n*p50, n*p50*(1.0-p50)))[0]\n",
    "    ks_b90[i] = scipy.stats.kstest(dist90, mynorm, args=(n*p90, n*p90*(1.0-p90)))[0]\n",
    "    ks_b99[i] = scipy.stats.kstest(dist99, mynorm, args=(n*p99, n*p10*(1.0-p99)))[0]\n",
    "    \n",
    "    #run the A-D tests.     \n",
    "    ad_b01[i] = scipy.stats.anderson(dist01, dist='norm')[0]\n",
    "    ad_b10[i] = scipy.stats.anderson(dist10, dist='norm')[0]\n",
    "    ad_b25[i] = scipy.stats.anderson(dist25, dist='norm')[0]\n",
    "    ad_b50[i] = scipy.stats.anderson(dist50, dist='norm')[0]\n",
    "    ad_b90[i] = scipy.stats.anderson(dist90, dist='norm')[0]\n",
    "    ad_b99[i] = scipy.stats.anderson(dist99, dist='norm')[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    mybins= np.linspace(min(dist01),max(dist01), 10) \n",
    "    bincenters = mybins[:-1]+0.5*(mybins[1]-mybins[0])\n",
    "    kl_b01 [i] =  scipy.stats.entropy(np.histogram(dist01, bins=mybins)[0], scipy.stats.norm.pdf(bincenters, loc=n*p01, scale=n*p01*(1.0-p01)))\n",
    "    kl_b10 [i] =  scipy.stats.entropy(np.histogram(dist10, bins=mybins)[0], scipy.stats.norm.pdf(bincenters, loc=n*p10, scale=n*p10*(1.0-p10)))\n",
    "    kl_b25 [i] =  scipy.stats.entropy(np.histogram(dist25, bins=mybins)[0], scipy.stats.norm.pdf(bincenters, loc=n*p25, scale=n*p25*(1.0-p25)))\n",
    "    kl_b50 [i] =  scipy.stats.entropy(np.histogram(dist50, bins=mybins)[0], scipy.stats.norm.pdf(bincenters, loc=n*p50, scale=n*p50*(1.0-p50)))\n",
    "    kl_b90 [i] =  scipy.stats.entropy(np.histogram(dist90, bins=mybins)[0], scipy.stats.norm.pdf(bincenters, loc=n*p90, scale=n*p90*(1.0-p90)))\n",
    "    kl_b99 [i] =  scipy.stats.entropy(np.histogram(dist99, bins=mybins)[0], scipy.stats.norm.pdf(bincenters, loc=n*p99, scale=n*p99*(1.0-p99)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Test Values as the Probablity Value changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot all figures\n",
    "fig = pl.figure(figsize = (15,5))\n",
    "fig.add_subplot(131)\n",
    "pl.plot(narray, ks_b01, label='KS .01')\n",
    "pl.plot(narray, ks_b10, label='KS .10')\n",
    "pl.plot(narray, ks_b25, label='KS .25')\n",
    "pl.plot(narray, ks_b50, label='KS .50')\n",
    "pl.plot(narray, ks_b90, label='KS .90')\n",
    "pl.plot(narray, ks_b99, label='KS .99')\n",
    "\n",
    "pl.legend()\n",
    "\n",
    "fig.add_subplot(132)\n",
    "pl.plot(narray, ad_b01, label='AD .01')\n",
    "pl.plot(narray, ad_b10, label='AD .10')\n",
    "pl.plot(narray, ad_b25, label='AD .25')\n",
    "pl.plot(narray, ad_b50, label='AD .50')\n",
    "pl.plot(narray, ad_b90, label='AD .90')\n",
    "pl.plot(narray, ad_b99, label='AD .99')\n",
    "\n",
    "pl.plot([narray[0], narray[-1]],[threshold, threshold])\n",
    "pl.plot()\n",
    "pl.plot()\n",
    "pl.legend()\n",
    "\n",
    "fig.add_subplot(133)\n",
    "pl.plot(narray, kl_b01, label='K-L .01')\n",
    "pl.plot(narray, kl_b10, label='K-L .10')\n",
    "pl.plot(narray, kl_b25, label='K-L .25')\n",
    "pl.plot(narray, kl_b50, label='K-L .50')\n",
    "pl.plot(narray, kl_b90, label='K-L .90')\n",
    "pl.plot(narray, kl_b99, label='K-L .99')\n",
    "\n",
    "\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Binomial v Normal Kolmogorov–Smirnov Tests\n",
    "The KS test measures the distance between two distributions.  Here, it takes as its inputs our randomly generated binomial distribution and a randomly generated normal distribution.  The result of the test is a measure of how close the two distributions are to being of the same value at any given point along the distribution.  Therefore a higher K-S value implies a greater distinction between distributions while a lowers K-S value implies the distributions are more alike.  Here as the sample size goes up, the value of the K-S statistic drops to “more or less” 0.2.  At very low values, the K-S statistic can be as high as 0.8.  There is some variation, or noise, around the value of 0.2 at larger sample sizes.  Therefore, we can say that the binomial, as the sample size goes up to above “about 10”, begins to closely approximate the normal distribution.\n",
    "\n",
    "### The Binomial v Normal – Anderson Darling Test\n",
    "\n",
    "Like the KS test, the AD test measures is used to test if a sample of data can be said to come from a stated distribution.  The AD test gives more weight to the tails of the distribution.  As the normal distribution shows the most variation at the tail, it is an excellent way to test if the sample is in fact normally distributed.  That being said, it can be used for other distributions as well.  Critical values are found in the samples CDF and compared to benchmarked critical values of known distributions.  Here, the lower the statistic, the lower the distance between critical values.  In our test, the AD score starts very high and exponentially decays as our sample grows lager.  At around a sample size of 10 or so, the statistic, while still decreasing, decreases at a lower rate.  This implies that the binomial distribution becomes more normal as the sample size increases.\n",
    "\n",
    "### The Binomial Kullback–Leibler Divergence Test\n",
    "The K-L test is a measure of information lost when one compares one sample distribution against another.  It measures the penalty one must pay to “construct” a distribution with instructions from a ‘true’ distribution.  The results here are similar to the K-S test and the A-D test.  The Binomial becomes rapidly more normal as the sample size increases.  At about 10, the rate of normalcy begins to tail off.  The distribution has quite a bit of ‘noise’ and oscillates around a relatively low value, but can differ from run to run significantly.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Process is repeated for the Possion Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "narray = range(1,50,1)\n",
    "ks_b = np.zeros(len(narray))\n",
    "ad_b = np.zeros(len(narray))\n",
    "kl_b = np.zeros(len(narray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,n in enumerate(narray):\n",
    "    p=0.1 #parameter for the binomial, my arbitrary choice\n",
    "    #generate the distribution\n",
    "    dist = np.random.poisson(n, 1000)\n",
    "    #run the tests. \n",
    "    ks_b[i] = scipy.stats.kstest(dist, mynorm, args=(n, n))[0]\n",
    "    ad_b[i] = scipy.stats.anderson(dist, dist='norm')[0]\n",
    "    \n",
    "        \n",
    "    # for KL and Pearson's chisq I have to simulate the normal distribution as well\n",
    "    mybins = np.linspace(min(dist),max(dist), 10) \n",
    "    bincenters = mybins[:-1]+0.5*(mybins[1]-mybins[0])\n",
    " \n",
    "    kl_b [i] =  scipy.stats.entropy(np.histogram(dist, bins=mybins)[0], scipy.stats.norm.pdf(bincenters, loc=n*p, scale=n*p*(1.0-p)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize = (15,5))\n",
    "fig.add_subplot(131)\n",
    "pl.plot(narray, ks_b, label='KS')\n",
    "pl.legend()\n",
    "\n",
    "fig.add_subplot(132)\n",
    "pl.plot(narray, ad_b,  label='AD')\n",
    "#pl.plot([narray[0], narray[-1]],[threshold, threshold])\n",
    "pl.plot()\n",
    "pl.plot()\n",
    "pl.legend()\n",
    "\n",
    "fig.add_subplot(133)\n",
    "pl.plot(narray, kl_b, label='K-L ')\n",
    "\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Possion v Normal Kolmogorov–Smirnov Tests\n",
    "The KS test measures the distance between two distributions.  Here, it takes as its inputs our randomly generated Possion distribution and a randomly generated normal distribution.  The result of the test is a measure of how close the two distributions are to being of the same value at any given point along the distribution.  Therefore a higher K-S value implies a greater distinction between distributions while a lowers K-S value implies the distributions are more alike.  Here as the mean increases, the Possion distribution gets closer to close to the normal distribution.  The drop off in the KS statstic levels off at a mean of 10 or so.\n",
    "\n",
    "### The Possion v Normal – Anderson Darling Test\n",
    "Like the KS test, the AD test measures is used to test if a sample of data can be said to come from a stated distribution.  The AD test gives more weight to the tails of the distribution.  As the normal distribution shows the most variation at the tail, it is an excellent way to test if the sample is in fact normally distributed.  That being said, it can be used for other distributions as well.  Critical values are found in the samples CDF and compared to benchmarked critical values of known distributions.  Here, the lower the statistic, the lower the distance between critical values.  In our test, the AD score starts very high and exponentially decays as our sample grows lager.  At around a sample size of 10 or so, the statistic, while still decreasing, decreases at a lower rate.  This implies that the Poisson distribution becomes more normal as the sample size increases, starting at a mean of around 10.\n",
    "\n",
    "### The Possion Kullback–Leibler Divergence Test\n",
    "The K-L test is a measure of information lost when one compares one sample distribution against another.  It measures the penalty one must pay to “construct” a distribution with instructions from a ‘true’ distribution.  The results here are similar to the K-S test and the A-D test.  The Binomial becomes rapidly more normal as the sample size increases.  At about 10, the rate of normalcy begins to tail off.  The distribution has quite a bit of ‘noise’ and oscillates around a relatively low value, but can differ from run to run significantly.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
